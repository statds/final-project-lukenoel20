---
title: "STAT 3255 Final Project"
subtitle: "NYC 311 Requests Analysis"
author: "Luke Noel"
jupyter: python3
format:
    html:
        embed-resources: true
---

## Introduction/Overview

I will be using the 311 Requests dataset from NYC Open Data, filtered to include requests made from 1/15/2023 to 1/21/23, just as we used in the midterm.

I will be doing a deep dive into the "Complaint Type" column. Here is an outline of some of what I will be covering:

+ Most popular complaint types
+ Relationship between time of day and complaint type
+ Honing in on "noise related" complaints
    + Noise vs. time of day
    + Noise vs. borough
    + Noise vs. median household income

This will include different visualizations, maps, and statistical tests of significance.

## Most Popular Complaint Types
```{python}
#| echo: false

import pandas as pd
import numpy as np

df = pd.read_csv('../data/nyc311_011523-012123_by022023.csv')

import matplotlib.pyplot as plt
import seaborn as sns
from scipy.stats import chi2_contingency
import warnings

# filter out the warning messages
warnings.filterwarnings('ignore', '.*')

# Count the number of complaints for each complaint type and borough
complaint_counts = df.groupby(['Complaint Type', 'Borough']).size().reset_index(name='count')

# Create a bar chart showing the counts for each complaint type
top_complaints = complaint_counts.groupby('Complaint Type')['count'].sum().sort_values(ascending=False).head(20).index.tolist()
top_complaint_counts = complaint_counts[complaint_counts['Complaint Type'].isin(top_complaints)]
sns.set(style="whitegrid")
plt.figure(figsize=(7,8))
ax = sns.barplot(x="count", y="Complaint Type", hue="Borough", data=top_complaint_counts, dodge=False, order=top_complaints)
ax.set_title('Top 20 Complaint Counts by Type and Borough')
plt.show()
```

+ Illegal Parking is the most frequent complaint called in to 311
+ Queens seems to be the borough with the most complaints
+ There is multiple noise related complaints, can we group them together?

## Top Complaints by Hour
```{python}
#| echo: false
# Create a pivot table of top 20 complaint types by hour of day
top_complaints = df['Complaint Type'].value_counts().nlargest(20).index.tolist()
df_top_complaints = df.loc[df['Complaint Type'].isin(top_complaints)]
df_top_complaints['hour'] = pd.to_datetime(df_top_complaints['Created Date']).dt.hour
pivot_df = df_top_complaints.pivot_table(index='hour', columns='Complaint Type', values='Unique Key', aggfunc='count')

# Heatmap of top 20 complaint types by hour of day
plt.figure(figsize=(8,8))
sns.heatmap(pivot_df, cmap='coolwarm', linecolor='white', linewidths=1)
plt.title('Top 20 Complaint Types by Hour of Day')
plt.xticks(rotation=45, ha='right')
plt.show()
```

+ Nothing extreme stands out, maybe besides Derelict Vehicles having a lot of calls at noon
+ Illegal Parking gets called in most during the day
+ Noise - Residential frequently called in at later hours of night, really early morning

## Most Popular Complaints (with noise group)
```{python}
#| echo: false

# Create a new column for "Noise Related" complaints
df['Complaint Group'] = df['Complaint Type'].apply(lambda x: 'Noise Related' if 'Noise' in x else x)

# Count the number of complaints for each complaint type and borough
complaint_counts = df.groupby(['Complaint Group', 'Borough']).size().reset_index(name='count')

# Create a bar chart showing the counts for each complaint type
top_complaints = complaint_counts.groupby('Complaint Group')['count'].sum().sort_values(ascending=False).head(20).index.tolist()
top_complaint_counts = complaint_counts[complaint_counts['Complaint Group'].isin(top_complaints)]

sns.set(style="whitegrid")
plt.figure(figsize=(7,8))
ax = sns.barplot(x="count", y="Complaint Group", hue="Borough", data=top_complaint_counts, dodge=False, order=top_complaints)
ax.set_title('Top 20 Complaint Counts by Type and Borough')
plt.show()
```

+ I grouped all complaints with "noise" in them
+ Noise related complaints are now 3rd most frequent
+ New complaints like WATER LEAK jump into the top 20 now

## Noise Complaints by Agency
```{python}
#| echo: false

df['noise'] = np.where(df['Complaint Group'] == 'Noise Related', 1, 0)
df.dropna(subset=['Latitude', 'Longitude'], inplace=True)

# Filter the DataFrame to only include rows where noise == 1
noise_df = df[df['noise'] == 1]

# Count the number of noise complaints by agency
agency_counts = df[df['noise'] == 1]['Agency Name'].value_counts()

# Plot the results as a bar graph
plt.figure(figsize=(7,6))
agency_counts.plot(kind='bar', color=['blue', 'red', 'maroon'])
plt.title('Number of Noise Complaints by Agency')
plt.xlabel('Agency')
plt.ylabel('Number of Complaints')
plt.xticks(rotation=45, ha='right')
plt.show()
```

+ Most noise complaints are to the NYPD
+ Interesting to see the other two agencies get noise related complaint requests
+ What is the difference between these agencies' noise complaints?

```{python}
#| echo: false

# Group the data by "Agency Name" and "Descriptor", count the number of complaints, and reset the index
grouped_df = noise_df.groupby(['Agency Name', 'Descriptor'])['Unique Key'].count().reset_index()

# Get a list of unique Agency Names
agency_names = grouped_df['Agency Name'].unique()

# Iterate over the Agency Names and print the top 5 descriptors for each
for agency_name in agency_names:
    print(f"Top 5 descriptors of noise complaints for the {agency_name}:")
    agency_df = grouped_df[grouped_df['Agency Name'] == agency_name].sort_values(by='Unique Key', ascending=False)
    top_5_descriptors = agency_df['Descriptor'].head(5).values.tolist()
    print(", ".join(top_5_descriptors))
    print()
```

+ Many "Other" entries for the EDC, NYPD descriptor?
+ Not much difference in general for descriptors to NYPD and DEP

## Noise Complaints By Hour
```{python}
#| echo: false

df['hour'] = pd.to_datetime(df['Created Date']).dt.hour

noise_pivot = df[df["noise"] == 1].pivot_table(index='hour', values='Unique Key', aggfunc='count')

# Plot the pivot table as a line chart
sns.lineplot(x=noise_pivot.index, y=noise_pivot['Unique Key'], color='blue')
plt.title("# of Noise Complaints by Hour of Day")
plt.xlabel("Hour of Day")
plt.ylabel("# of Noise Complaints")
plt.show()
```

+ Noise complaints happen most frequently during the early morning and late night hours
+ A dip in the middle of the day
+ Makes sense, during the day people work and/or don't really care about loud noises as much as when they are trying to sleep

## Noise Complaints By Day of the Week
```{python}
#| echo: false

# Create a new column with the day of the week
noise_df['day_of_week'] = pd.to_datetime(noise_df['Created Date']).dt.day_name()

# Convert "day_of_week" column to a categorical data type with the desired order
day_order = ["Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday"]
noise_df["day_of_week"] = pd.Categorical(noise_df["day_of_week"], categories=day_order, ordered=True)

# Count the number of noise complaints per day of the week
day_counts = noise_df['day_of_week'].value_counts()

# Create bar plot of noise complaints per day of the week
plt.figure(figsize=(10,6))
sns.barplot(x=day_counts.index, y=day_counts.values, palette='bright')
plt.title("Number of Noise Complaints per Day of the Week", fontsize=16)
plt.xlabel("Day of the Week", fontsize=14)
plt.ylabel("Number of Complaints", fontsize=14)
plt.xticks(rotation=45, ha='right')
plt.show()
```

+ Noise complaints are called in most on Saturdays and Sundays
+ Why is this? Possibilities:
    + Parties / get-togethers happen on weekends, can be loud
    + People are off of work so they are at home and have all day to call in a noise complaint
+ Is the difference between frequencies during weekdays vs. weekends statistically significant?
    + Split data into those two categories

### Testing difference between weekdays/weekends
Split the data into two groups, weekends (Friday, Saturday, and Sunday) and weekdays (the rest)

```{python}
#| echo: false

import numpy as np

df['day_of_week'] = pd.to_datetime(df['Created Date']).dt.day_name()

weekdays = df[df['day_of_week'].isin(['Monday', 'Tuesday', 'Wednesday', 'Thursday'])]
weekends = df[df['day_of_week'].isin(['Friday', 'Saturday', 'Sunday'])]

mean_weekdays = np.mean(weekdays['noise'])
std_weekdays = np.std(weekdays['noise'])

mean_weekends = np.mean(weekends['noise'])
std_weekends = np.std(weekends['noise'])
fig, ax = plt.subplots()

labels = ['Weekday', 'Weekend']
sizes = [mean_weekdays, mean_weekends]
colors = ['#4FB0C6', '#87C540']

ax.pie(sizes, labels=labels, colors=colors,
       autopct='%1.1f%%', startangle=90, pctdistance=0.75, labeldistance=1.1, textprops={'fontsize': 14})

# set aspect ratio to be equal so that pie is drawn as a circle
ax.axis('equal')  
plt.title('Proportion of Noise Complaints by Day Type', fontsize=16)

plt.show()
```

+ Is this difference statistically significant?
    + Ho: Total # of noise complaints are equal between weekday group and weekend group
    + Ha: Total # of noise complaints on weekends is larger than the total on weekdays
+ Two sample T-test (alpha=0.05):

```{python}
#| echo: false

from scipy.stats import ttest_ind

t_stat, p_val = ttest_ind(weekdays['noise'], weekends['noise'])

print("P-value:", p_val)

if p_val < 0.05:
    print("The total number of noise complaints is significantly greater on weekends than weekdays.")
else:
    print("There is no significant difference in the frequency of noise complaints between weekdays and weekends.")
```

## Noise Complaints by Borough
```{python}
#| echo: false
# Count of noise complaints by borough
noise_borough = df[df['noise'] == 1].groupby('Borough').size().reset_index(name='count')
noise_borough = noise_borough.sort_values('count', ascending=False)

# Set the color palette
colors = sns.color_palette('bright', len(noise_borough))

# Create the bar plot
plt.figure(figsize=(10,6))
plt.bar(noise_borough['Borough'], noise_borough['count'], color=colors)
plt.title('Number of Noise Complaints Per Borough')
plt.xlabel('Borough')
plt.ylabel('Count')
plt.xticks(rotation=45, ha='right')
plt.show()
```

+ Most people who called in noise complaints live in Manhattan
+ Is the difference of the counts between boroughs statistically significant?

### Testing difference between boroughs

+ Chi-Squared Test (alpha=0.05)
    + Ho: No significant difference of the count of noise complaints between each of the 5 boroughs
    + Ha: There is a significant difference between the count of noise complaints across the 5 boroughs

```{python}
#| echo: false

import scipy

# Chi-squared test for noise complaints by borough
noise_counts = noise_df['Borough'].value_counts()
borough_counts = df['Borough'].value_counts()
observed = noise_counts.reindex(borough_counts.index, fill_value=0)
expected = borough_counts * (observed.sum() / borough_counts.sum())

chi2, p, dof, expected = scipy.stats.chi2_contingency([observed, expected])

print(f"Chi-squared test statistic: {chi2}")
print(f"p-value: {p}")
```

+ P-value is very small (less than alpha) so we can reject the null hypothesis
    + Conclude that there is a significant difference between the count of noise complaints across the boroughs
+ Can we visualize this difference on a map of NYC?

## Map of Noise Complaints

```{python}
#| echo: false

import gmplot
from apikey import api_key


df = df[df['Borough'] != 'Unspecified']

# Create a subset of the data for noise complaints only
noise_df = df[df['noise'] == 1]

# Group the dataframe by the "BOROUGH" column
borough_groups = noise_df.groupby('Borough')

# Creating a map centered around NYC with the location points scattered
gmap = gmplot.GoogleMapPlotter.from_geocode('New York City', 10, apikey=api_key)

# Loop through each group and plot the points with a different color for each borough
colors = ['red', 'blue', 'green', 'brown', 'purple'] # define a list of colors for each borough
for i, (borough, group) in enumerate(borough_groups):
    gmap.scatter(group['Latitude'], group['Longitude'], marker=False, size=75, color=colors[i])

# Draw the map
gmap.draw('noise_map.html')
```

![noise_map.png](noise_map.png)

+ Manhattan (green dots) looks to have the most # of noise complaints, which matches the bar chart above
+ Not many around the airport (JFK), surprising
+ If you want a quiet neighborhood you may want to live in Staten Island

## Any other relationships we can explore?

### Median Household Income vs. Noise Complaints

+ Merged the 311 Requests dataset with the Uszipcode SQL database (on the Zipcode key)
+ Median household income may have a relationship with # of noise complaints
    + Do "richer" neighborhoods call in more noise complaints?
        + At the zip code level (i.e each individual point will be the count of noise complaints per zip code, with the corresponding median household income for that zip code)

```{python}
#| echo: false

from uszipcode import SearchEngine, SimpleZipcode, ComprehensiveZipcode
import sqlite3

# Removing the .0 and changing to str to match zip code database
noise_df['Incident Zip'] = noise_df['Incident Zip'].astype(str).str[:-2]

# Retrieving database from uszipcode and assigning it to zipc (dataframe)
with sqlite3.connect("/Users/lukesmac/.uszipcode/simple_db.sqlite") as con:
    zipc = pd.read_sql_query("SELECT * from simple_zipcode", con)

# Merging the two dataframes using zip code key, assigning to new dataframe
noise_zip = pd.merge(noise_df, zipc, how='left', left_on='Incident Zip', right_on='zipcode')

# Group data by zip code and count the number of rows for each group
num_complaints = noise_zip.groupby('Incident Zip')['Unique Key'].count()

# Convert the series to a dataframe
df_num_complaints = pd.DataFrame(num_complaints.reset_index())

df_num_complaints = df_num_complaints.rename(columns={'Unique Key': 'count'})

count_zip = pd.merge(df_num_complaints, zipc, how='left', left_on='Incident Zip', right_on='zipcode')

# create a scatter plot of median household income vs number of noise complaints, with color representing population
plt.scatter(count_zip['median_household_income'], count_zip['count'], c=count_zip['population'], cmap='viridis')

# add axis labels and a title
plt.xlabel('Median Household Income')
plt.ylabel('Number of Noise Complaints')
plt.title('Relationship between Median Household Income and # of Noise Complaints')

# add a colorbar legend
cb = plt.colorbar()
cb.set_label('Population')

# show the plot
plt.show()

# Calculate correlation coefficient
correlation = count_zip['median_household_income'].corr(count_zip['count'])

print('Correlation coefficient:', correlation)
```

+ We actually see a negative relationship between these two variables as the correlation coefficient is negative
    + Not significant of a number to draw any conclusions though
+ Population is included on the graph (the lighter the color, the greater the population is in that zip code)
    + The greater the population, the more noise complaints
+ Outliers?
    + The zip code point with over 350 complaints
    + The points with higher than $150,000 median household income
        + Very low population makes that much

## Recap/Conclusion

+ Many different complaints get called into 311 in NYC
    + Most popular: Illegal Parking and Noise related

+ Noise complaint relationships with other factors:
    + Hour:
        + They happen more frequent in early morning, late night
    + Agencies:
        Most get called into NYPD; DEP and EDC are the two others
    + Boroughs:
        + Manhattan has the most, Staten Island the least
        + Difference across the 5 boroughs is statistically significant
    + Day of the Week:
        + Most happen on weekends
        + Difference between freq. on weekdays/weekends is statistically significant
    + Median Household Income / Population:
        + Weak relationship with household income
        + Greater the pop. the more noise complaints get called in, makes sense

All in all, I think this analysis could be useful for the NYC government, as they can learn patterns of where noise complaints happen, who they get called in to, and the times when they happen the most.

It can also be useful for the citizens of NY, as they can learn where the "quietest" times/locations of NYC are.